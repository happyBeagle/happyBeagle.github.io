---
title: "[머신러닝 기초]-Begin"
layout: single
author_profile: true
read_time: true
comments: true
share: true
related: true
categories:
- Machine-Learning
tags:
- Machine-Learning_basic
toc: true
toc_sticky: true
toc_label: contents
description: 머신러닝 기초에 대해 학습합니다.
---

## 머신러닝이란?
**Arthur Samuel (1959):** "Field of study that gives computers the ability to learn without being explicitly programmed"  
--> 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야이다.   
**Tom Mitchell (1997):** "어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정하였을 때 경험 E로 인해 성능이 향상되었다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한것이다." 
## 머신러닝의 분류
### 1. Supervised Learning VS Unsupervised Learning 
#### Supervised Learning 
**지도 학습**이라고 한다. 프로그램이 학습을 할때 사용되어지는 training data에 Label이라고 하는 답이 포함이 된다.  
주로 **Classification(분류)** 가 전형적인 지도학습 작업이다.  
예를 들어 스팸 필터를 생각해보자.  

1. 사용자가 수신한 메일이 스팸인지 아닌지 분류를 하기 위해 스팸 필터는 학습을 할 것이다. 
2. 이때 스팸 필터가 학습을 하기 위해 사용되는 **training data**에는 **메일의 특성**과 **해당 메일이 스팸인지 아닌지에 대한 정보**가 포함되어 있다. 
3. 여기서 메일의 특성은 예측변수가 되는 것이며 해당 메일의 스팸여부는 Label이 된다. 

이렇게 학습을 할때 training data에 결과값이 포함되는 것을 **지도 학습**이라고 한다. 

또한 지도학습에는 **Regression(회귀)** 라고하는 작업도 존재한다.   
**회귀**는 예측변수라고 불리는 특성을 사용해 수치를 예측하는 것을 말한다. 
일부 회귀알고리즘은 분류에도 사용할 수 있고 반대의 경우도 존재한다. 

**Supervised Learning 종류**

* K-Nearest Neighbors (K-최근접 이웃) 
* Linear Regression (선형 회귀) 
* Logistic Regression (로지스틱 회귀) 
* Support Vector Machines (서포트 벡터 머신_SVM) 
* Decision Tree & Random Forest (결정트리 & 랜덤 포레스트) 
* Neural Networks (신경망) 

#### Unsupervised Learning
**비지도 학습**이라고 한다. 말 그대로 training data에 Label이 존재하지 않는다. 
**Clustering(군집)** 알고리즘이 대표적인 예이다.  
예를 들어 비슷한 방문자들을 그룹으로 묶기위해 해당 알고리즘을 사용한다고 생각해보자. 

1. 방문자들의 정보를 수집하여 시도한다. 
2. 하지만 방문자가 어떤 그룹에 속하는 지 알려 줄 수 있는 데이터 포인트를 알 수 없다.
3. 알고리즘이 스스로 방문자들의 연결고리를 찾아 답을 도출한다.

그 외에도 **Visualization(시각화)** 알고리즘은 Label이 없는 대규모의 고차원 데이터를 넣으면 도식화가 가능한 2D나 3D 표현을 만들어 준다.
비슷한 작업으로는 정보의 손실을 최소화하면서 데이터를 간소화 하는 **Dimensionality Reduction(차원 축소)** 알고리즘이 존재한다.

**Unsupervised Learning 종류**
* Clustering (군집)
	* K-Means (K-평균)
	* Hierarchical Cluster Analysis (계층 군집 분석_HCA)
	* Expectation Maximization (기댓값 최대화)
* Visualizaion & Dimensionality Reduction (시각화 & 차원 축소)
	* Principal Component Analysis (주성분 분석_PCA)
	* kernel PCA
	* Locally-Linear Embedding (지역적 선형 임베딩_LLE)
	* t-distributed Stochastic Neighbor Embedding (t-SNE)
* Association Rule Learning (연관 규칙 학습)
	* Apriori (어프라이어리)
	* Eclat (이클렛)

#### Others
* **1.Semisupervised Learning**
**준지도 학습**이라고 한다.  
이는 Label이 일부만 있는 데이터를 다룰 때 사용된다. 
구글 포토 호스팅이 이에 해당되는 예시라고 생각할 수 있다. 

1. 단체사진을 해당 서비스에 업로드한다.
2. A는 사진 a, c, d에 있고 B는 e, f에 있다고 자동 인식한다.
3. 이것은 비지도 학습이다.
4. 여기서 A와 B가 누구인지 식별하는 것은 지도 학습에 속한다.

	* **종류**
		* Deep Belief Network(DBN)은 제한된 볼츠만 머신이라 불리는 비지도 학습에 기초한다.
* **2.Reinforcement Learning**
**강화 학습**이라고 한다.
학습하는 시스템을 **에이전트**라고 부르며 환경을 관찰해서 행동을 하고 그 결과로 **보상** 또는 **벌점**을 받는다. 
시간이 지나면서 더 큰 보상을 얻기 위해 **정책**이라는 최상의 전략을 스스로 학습한다. 


### 2. Batch Learning VS Online Learning
#### Batch Learning
**배치 학습**이다. 해당 방법에서는 시스템이 점진적으로 학습할 수 없다.  
가용한 데이터를 모두 사용하여 훈련시켜야한다. 
--> 따라서 시간과 자원이 많이 소모되므로 주로 오프라인에서 수행된다. 
--> 먼저 시스템을 훈련시키고 제품 시스템에 적용시키면, 더 이상의 학습없이 프로그램이 실행된다.
==> 그래서 **Offline Learning(오프라인 학습)** 이라고 한다.

#### Online Learning
**온라인 학습**이다. 해당 방법에서는 데이터를 순차적으로 한 개씩 또는 미니 batch라고 불리는 작은 묶음 단위로 주입하여 훈련 시킨다.
매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 데로 즉시 학습이 가능하다.
--> 컴퓨터 자원이 제한 된 경우에 유용하다.
--> 학습을 완료한 데이터는 제거하면 되므로 많은 공간이 절약된다.


## 참고
* Hands-On Machine Learning with scikit-Learn & TensorFlow : 1장. 한눈에 보는 머신러닝
